"""
Production Ready ETL
- create/reads Sqlite transactions table (readymade data)
- Exports table in CSV
- Reads local customer CSV
- Inner Joins on Account Number
- Applies transformations and currency conversions
- Aggregate by Branch Code and transactions Type
- writes final csv report
- Robust logging,validation,error Handling
"""
from pathlib import Path
import sqlite3
import pandas as pd
import logging
from logging.handlers import RotatingFileHandler
import sys
from typing import Dict,Tuple


# ------ App Configuration----------
BASE_DIR= Path("temp")
DB_FILE=BASE_DIR / "banking.db"
DB_EXPORT_CSV=BASE_DIR / "db_export.csv"
CUSTOMER_CSV=BASE_DIR / "customer_details.csv"
FINAL_REPORT_CSV=BASE_DIR / "final_report.csv"
LOG_FILE=BASE_DIR / "banking_etl.log"

CONVERSION_RATES: Dict[str, float] = {
    "USD": 1.000,
    "EUR": 1.08,
    "INR": 0.011

}
REQUIRED_DB_COLUMNS={
    "Account_Number","Customer_Name","Branch_Code","Transaction_Type","Transaction_Date",
    "Transaction_Amount","Balance","Currency","Account_Status"
}
#-------- setup logs----
def setup_logging(log_file: Path) -> None:
    log_file.parent.mkdir(parents=True, exist_ok=True)
    logger = logging.getLogger()
    logger.setLevel(logging.DEBUG)
    fmt = logging.Formatter("%(asctime)s - %(name)s - %(levelname)s - %(message)s")

    # console Handlers
    ch=logging.StreamHandler(sys.stdout)
    ch.setLevel(logging.INFO)
    ch.setFormatter(fmt)
    logger.addHandler(ch)

    # Rotating File Handler
    fh=RotatingFileHandler(LOG_FILE, maxBytes=5 * 1024 * 1024, backupCount=3)
    fh.setLevel(logging.DEBUG)
    fh.setFormatter(fmt)
    logger.addHandler(fh)
logger=logging.getLogger(__name__)

#------ DB App---------------
def init_sqlite_with_dummy_data(db_path: Path) -> None:
    """
    Create SQLite DB with dummy data and insert transaction record if table is empty

    """
    logger.debug("Initializing SQLite DB at %s", db_path)
    db_path.parent.mkdir(parents=True, exist_ok=True)
    try:
        with sqlite3.connect(db_path) as conn:
            cur= conn.cursor()
            cur.execute("""
                CREATE TABLE IF NOT EXISTS transactions (
                    Account_Number INTEGER,
                    Customer_Name TEXT,
                    Branch_Code TEXT,
                    Transaction_Date TEXT,
                    Transaction_Type TEXT,
                    Transaction_Amount REAL,
                    Balance REAL,
                    Currency TEXT,
                    Account_Status TEXT
                )    
            """)
            # Insert only if Empty
            cur.execute("select count(1) from transactions")
            count= cur.fetchone()[0]
            if count == 0:
                logger.info("Inserting dummy data into transaction table")
                transactions_data =[
                    (1001,'Daniel White','B001','2024-01-15','Deposit',5000,15000,'usd','Active'),
                    (1002,'alice Smith','B002','2024-02-10','Withdraw',2000,8000,'inr','Active'),
                    (1003, 'Bob Johnson', 'B003', '2024-02-22', 'Deposit', 3000, 9000, 'usd', 'Closed'),
                    (1004, 'Clara Osward', 'B004', '2024-03-05', 'Deposit', 4000, 5000, 'eur', 'Active'),
                    (1005, 'Amit verma', 'B005', '2024-03-11', 'Withdraw', 3000, 92000, 'inr', 'Active'),
                ]
                cur.executemany("""
                    INSERT INTO transactions
                    (Account_Number,Customer_Name,Branch_Code,Transaction_Date,Transaction_Type,
                     Transaction_Amount,Balance,Currency,Account_Status)
                     Values (?,?,?,?,?,?,?,?,?)
                """,transactions_data)
                conn.commit()
                logger.debug("Dummy Data Commited to DB")
            else:
                logger.info("Transaction record already Populated (%d rows)", count)
    except sqlite3.Error as e:
        logger.exception("Error while connecting to SQLite database: %s", e)
        raise

def export_table_to_csv(db_path:Path,csv_path: Path, table_name:str='transactions') -> None:
    """
    Read Date from table abd write to CSV
    """
    logger.debug("Exporting table %s from DB %s to CSV at %s", table_name,db_path,csv_path)
    try:
        with sqlite3.connect(str(db_path)) as conn:
            df= pd.read_sql_query(f"SELECT * FROM {table_name}", conn)
        if not REQUIRED_DB_COLUMNS.issubset(df.columns):
            missing= REQUIRED_DB_COLUMNS - set(df.columns)
            raise ValueError(f"Missing columns: {missing}")
        csv_path.parent.mkdir(parents=True, exist_ok=True)
        df.to_csv(csv_path, index=False)
        logger.info("Exported %d rows to %s", len(df), csv_path)
    except Exception:
        logger.exception("FAiled to export DB to CSV")
        raise
#---- CSV & Transformation Utilities
def read_csv_validation(path: Path, required_columns: set) -> pd.DataFrame:
    logger.debug("Reading CSV %s", path)
    if not path.exists():
        msg= f"CSV file not found: {path}"
        logger.error(msg)
        raise FileNotFoundError(msg)

    df= pd.read_csv(path)
    logger.debug("Loaded %d rows %s", len(df),path)
    missing=required_columns - set(df.columns)
    if missing:
        msg= f"CSV {path} is missing required columns: {missing}"
        logger.error(msg)
        raise ValueError(msg)
    return df
def transform_and_aggregate(df_db: pd.DataFrame, df_cust: pd.DataFrame,
                            conversion_rates: dict[str, float])-> Tuple[pd.DataFrame, pd.DataFrame]:
    """
    Performs joins,transformations,filter and aggregation
    Returns (joined_df,report_df)
   """
    logger.info("Joining DB and customer data on Account_Number")
    df= pd.merge(df_db,df_cust,on='Account_Number',how='inner',validate='one_to_one')
    logger.debug("Joined DF shapes: %s", df.shape)

    # standardize the name
    logger.debug("Standardizing Customer_Name to title case")
    df['Customer_Name']=df['Customer_Name'].astype(str).str.title()

    # Transaction date -> datetime,extract year/month
    logger.debug("Parsing Transaction_Date and extracting year/month")
    df['Transaction_Date']=pd.to_datetime(df['Transaction_Date'],errors='coerce')
    if df['Transaction_Date'].isnull().any():
        bad_rows=df[df['Transaction_Date'].isnull()]
        logger.warning("Some Transaction_Date rows could not be parsed, Example rows: %s ",bad_rows.head().to_dict(orient='records'))
        df= df.dropna(subset=['Transaction_Date'])
        logger.debug("Dropped row with invalid Transaction_Date column")
    df['Transaction_Year']= df['Transaction_Date'].dt.year
    df['Transaction_Month']= df['Transaction_Date'].dt.strftime('%b')

    # currency normalization
    logger.debug("Normalizing currency to uppercase")
    df['Currency']=df['Currency'].astype(str).str.upper()

    # filter out closed accounts
    logger.info('filter out closed accounts with account_status=closed')
    df_active= df[df['Account_Status'].str.strip().str.upper() != 'CLOSED'].copy()
    logger.debug("Active DF shape: %s",df_active.shape)

    # convert to USD using conversion rates

    def convert_to_usd(row):
        cur=str(row['Currency']).upper()
        rate= conversion_rates.get(cur)
        if rate is None:
            logger.warning("Unknown currency '%s'", cur)
            rate=1.0
        return  row['Transaction_Amount']*rate

    logger.debug('calculating Transaction Amount')
    df_active['Transaction_Amount_USD']=df_active.apply(convert_to_usd,axis=1)

    # aggregate
    logger.info('Aggregating by branch code and transaction type')
    report=(
        df_active.groupby(['Branch_Code','Transaction_Type'],dropna=False)
        .agg(
         Transaction_Count= ('Transaction_Amount','count'),
         Total_Amount_USD= ('Transaction_Amount_USD','sum'),
        ).reset_index()
    )
    logger.debug('Report shape %s', report.shape)
    return df_active, report
def run():
    try:

        setup_logging(LOG_FILE)
        logger.info(f"Logging to {LOG_FILE}")
        # step-1 initialize the db with dummy data
        init_sqlite_with_dummy_data(DB_FILE)
        # export db to csv
        export_table_to_csv(DB_FILE,DB_EXPORT_CSV)
    except Exception as exc:
        logger.exception("Error while connecting to SQLite database: %s", exc)
    return  1
if __name__ == "__main__":
    exit_code=(run())
    sys.exit(exit_code)



